#!/usr/bin/env python3
"""
scoring_v2.py
Versi√≥n: 2.0 (v1.7)

Este m√≥dulo contiene una implementaci√≥n actualizada del sistema heur√≠stico de
scoring para priorizar URLs sospechosas de phishing orientadas a usuarios en
Espa√±a.  La versi√≥n 2 incorpora las lecciones aprendidas durante el an√°lisis
del conjunto de datos con puntuaciones intermedias (score 4‚Äì7) y ampl√≠a las
reglas de la versi√≥n 1 con se√±ales adicionales relativas al contexto,
infraestructura y patrones ling√º√≠sticos.  Las reglas est√°n documentadas en
los comentarios y deben mantenerse sincronizadas con el documento
``docs/scoring.md``.

Principales novedades respecto a la v1:

* Refuerzo de la combinaci√≥n ``marca + tokens en espa√±ol``, que punt√∫a
  significativamente cuando una marca espa√±ola coincide con alg√∫n t√©rmino
  castellano en el dominio, subdominio o ruta.
* Detecci√≥n de marcas dentro de la ruta (``brand_in_path``) adem√°s de en el
  dominio o subdominio.
* Identificaci√≥n de tokens de verificaci√≥n en la ruta (``sms``, ``codigo``,
  ``pin``, ``verificacion``, ``clave``, ``recibir``, ``particulares``,
  ``espera``) mediante la regla ``path_verification_tokens``.
* Reconocimiento de infraestructuras de alojamiento sospechosas y TLDs de
  alto riesgo, otorgando puntos cuando coexisten con contexto espa√±ol y
  penalizando en ausencia de se√±ales en castellano.
* Penalizaci√≥n de t√©rminos ingleses en la ruta o dominio cuando aparecen
  junto a marcas espa√±olas (``english_term_in_path``), para filtrar ruido de
  campa√±as globales.
* Gesti√≥n de falsos positivos en torno a la cadena ``ing`` (``ing_false_positive``
  e ``ing_path_exception``), inspirada en la funci√≥n ``detect_ing_brand``
  desarrollada durante el an√°lisis.
* Extensi√≥n de la lista de hostings gratuitos y proveedores de subdominios
  explotados por phishers.
* Identificaci√≥n de dominios ``.es`` comprometidos mediante la detecci√≥n de
  rutas t√©cnicas t√≠picas de WordPress (``wp-``, ``plugins``, ``includes``, etc.),
  etiquet√°ndolos como ``compromised_host_es``.

Estas reglas buscan mejorar la sensibilidad frente a campa√±as reales sin
incrementar excesivamente los falsos positivos.  La puntuaci√≥n resultante se
utiliza para filtrar y priorizar URLs en el pipeline de limpieza.
"""

import sys
import logging
import re
from pathlib import Path
from datetime import datetime
from urllib.parse import urlparse

import pandas as pd
from rapidfuzz import fuzz

logger = logging.getLogger("scoring_v2")
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")


# ---------------------------------------------------------------------------
#  Carga de whitelist
# ---------------------------------------------------------------------------
def load_spanish_whitelist(path: Path) -> list:
    """
    Carga un fichero de dominios espa√±oles de referencia (CSV o TXT) y
    devuelve una lista de cadenas en min√∫sculas.  Se utiliza tanto para
    coincidencias exactas como para coincidencias difusas (fuzzy matching) en
    la funci√≥n de scoring.

    :param path: Ruta del fichero de whitelist.
    :return: Lista de dominios en min√∫sculas.
    """
    path = Path(path)
    if not path.exists():
        raise FileNotFoundError(f"‚ùå Whitelist no encontrada: {path}")
    try:
        df = pd.read_csv(path)
        col = df.columns[0]
        return df[col].astype(str).str.lower().str.strip().tolist()
    except Exception:
        with open(path, "r", encoding="utf-8") as f:
            return [line.strip().lower() for line in f if line.strip()]


# ---------------------------------------------------------------------------
#  Reglas y listas de se√±ales
# ---------------------------------------------------------------------------

# Marcas espa√±olas conocidas (banca, log√≠stica, administraci√≥n, telecomunicaciones)
SPANISH_BRANDS = [
    'santander', 'bbva', 'caixabank', 'bankinter', 'ing', 'unicaja',
    'correos', 'aeat', 'dgt', 'ionos', 'orange', 'movistar', 'mapfre',
    'seg-social', 'gobierno', 'dhl', 'seur', 'bbvaabank'
]

# Tokens gen√©ricos en castellano (clientes, transacciones, env√≠os, administraci√≥n)
SPANISH_TOKENS = [
    'cliente', 'clientes', 'tarjeta', 'pago', 'pagos', 'factura', 'facturas',
    'multa', 'acceso', 'login', 'entrada', 'inicio', 'sesion', 'seguridad',
    'confirmacion', 'verificacion', 'envio', 'entrega', 'paquete', 'paquetes',
    'pedido', 'pedidos', 'datos', 'perfil', 'cuenta', 'cuentas', 'portal',
    'notificacion', 'notificaciones', 'aviso', 'mensajeria', 'mensaje', 'mensajes',
    'actualizacion', 'renovar', 'renovacion', 'certificado', 'usuario', 'usuarios',
    'banco', 'banca', 'oficina', 'oficinavirtual', 'movil', 'bancamovil',
    'suscripcion', 'compra', 'compras', 'recibo', 'recibos', 'gob', 'oficial',
    'tramite', 'tramites', 'agencia', 'impuestos', 'dni', 'salud', 'sanidad',
    'seg-social', 'particulares', 'forma', 'espera', 'recibir', 'codigo', 'clave',
    'sms', 'pin', 'verificacion', 'token', 'firma', 'validacion'
]

# Detectores de tokens de verificaci√≥n presentes en rutas de phishing bancario
VERIFICATION_TOKENS = [
    'sms', 'codigo', 'pin', 'verificacion', 'clave', 'token', 'pin', 'dni',
    'recibir', 'espera', 'forma', 'codigo_incorrecta', 'codigo_incorrecto'
]

# Marcadores geogr√°ficos o monetarios espa√±oles
SPANISH_MARKERS = ['.es', '+34', '‚Ç¨']

# Hostings espa√±oles gratuitos o ampliamente utilizados por campa√±as en castellano
SPANISH_HOSTINGS = [
    'webcindario', 'rf.gd', 'tempurl.host', '10web.site', 'freewebhostmost.com',
    'preview-domain.com', 'codeanyapp.com', 'fsthosting.com', 'cprapid.com',
    'suportededicado.net', 'page.link', 'firebaseapp.com', 'web.app', 'appspot.com',
    'pages.dev', 'weebly.com'
]

# TLDs de alto riesgo frecuentemente abusados en phishing (gTLDs baratos)
RISKY_TLDS = [
    '.xyz', '.top', '.shop', '.bond', '.info', '.vip', '.cc', '.online',
    '.lol', '.site', '.casa', '.cloud', '.live', '.host', '.support',
    '.review', '.link', '.app', '.dev', '.ml', '.tk', '.ga', '.cf'
]

# TLDs latinoamericanos que suelen usarse en campa√±as fuera de Espa√±a
LATAM_TLDS = [
    '.co', '.mx', '.cl', '.ar', '.br', '.pe', '.ec', '.uy', '.py', '.bo',
    '.sv', '.hn', '.cr', '.gt', '.do'
]

# Tokens portugueses que indican contenido no espa√±ol
PORTUGUESE_TOKENS = ['pagamento', 'fatura', 'faturas', 'acesso', 'conta', 'cliente-pt']

# Marcas latinoamericanas o bancos regionales para descartar
LATAM_BRANDS = ['banrural', 'pichincha', 'itau', 'bradesco', 'yape', 'daviplata']

# Palabras inglesas frecuentes en campa√±as globales que se penalizan cuando
# aparecen en URLs con marcas espa√±olas
ENGLISH_TOKENS = [
    'reset', 'secure', 'security', 'details', 'update', 'validation', 'validate',
    'online', 'account', 'user', 'users', 'customer', 'customers', 'payees',
    'authorize', 'authorization', 'login', 'access', 'confirm', 'payment',
    'invoice', 'billing', 'statement', 'service', 'services', 'support',
    'details', 'sessions', 'portal'
]

# Patrones de hostings ef√≠meros basados en "ingress" y dominios .ewp.live
INGRESS_REGEX = re.compile(r"ingress-[a-z0-9]+\.ewp\.live")


def _extract_core_domain(netloc: str) -> str:
    """Extrae el segundo nivel de dominio para fuzzy matching."""
    parts = netloc.split('.')
    return parts[-2] if len(parts) >= 2 else netloc


def score_url_v2(url: str, spanish_whitelist: list):
    """
    Calcula la puntuaci√≥n heur√≠stica de una URL seg√∫n la versi√≥n 2 del modelo.
    Devuelve una tupla (score:int, signals:str).
    """
    url_low = str(url).lower()
    parsed = urlparse(url_low)
    netloc = parsed.netloc or ''
    path = parsed.path or ''
    query = parsed.query or ''

    # El core del dominio (sin TLD) para fuzzy matching de marcas y whitelist
    core = _extract_core_domain(netloc)

    score = 0
    signals = []

    # ------------------------------------------------------------------
    # 1. Detectar marcas espa√±olas y tokens castellanos
    # ------------------------------------------------------------------
    has_spanish_brand = False
    for b in SPANISH_BRANDS:
        if b in url_low:
            score += 1
            signals.append(f'spanish_brand:{b}')
            has_spanish_brand = True

    # Tokens en espa√±ol (palabras clave)
    spanish_token_count = 0
    for tok in SPANISH_TOKENS:
        if tok in url_low:
            score += 1
            signals.append(f'spanish_token:{tok}')
            spanish_token_count += 1

    # Marcadores .es, +34, ‚Ç¨
    for marker in SPANISH_MARKERS:
        if marker in url_low:
            # Bonus mayor para .es; euro y +34 suman 1
            if marker == '.es':
                score += 2
            else:
                score += 1
            signals.append(f'spanish_marker:{marker}')

    # Hostings espa√±oles o comunes en phishing hispano
    for host in SPANISH_HOSTINGS:
        if host in netloc:
            score += 2
            signals.append(f'spanish_hosting:{host}')

    # --------------------------------------------------------------
    # 2. Combos y contextos
    # --------------------------------------------------------------
    # Marca + token espa√±ol: se√±al fuertemente indicativa
    if has_spanish_brand and spanish_token_count >= 1:
        score += 3
        signals.append('brand_and_spanish_token_boost')

    # Marca en el path (no solo en host)
    # Excluimos la coincidencia en netloc para evitar duplicados
    path_lower = path.lower()
    for b in SPANISH_BRANDS:
        if b in path_lower and b not in netloc:
            score += 2
            signals.append(f'brand_in_path:{b}')
            break

    # Tokens de verificaci√≥n en path
    for vt in VERIFICATION_TOKENS:
        if vt in path_lower:
            score += 2
            signals.append(f'path_verification_tokens:{vt}')
            break

    # Marca en subdominio (por ejemplo, bbva-login.com)
    try:
        subdomain = '.'.join(netloc.split('.')[:-2])
        if subdomain:
            for b in SPANISH_BRANDS:
                if b in subdomain:
                    score += 2
                    signals.append('brand_in_subdomain')
                    break
    except Exception:
        pass

    # Marca espa√±ola en TLD global (com, net, org, app, etc.)
    has_es_in_netloc = '.es' in netloc
    if has_spanish_brand and any(netloc.endswith(tld) for tld in ['.com', '.net', '.org', '.app', '.dev']) and not has_es_in_netloc:
        score += 2
        signals.append('brand_global_tld_boost')

    # Dominio con TLD de alto riesgo y contexto espa√±ol ‚Üí boost moderado
    if any(netloc.endswith(tld) for tld in RISKY_TLDS):
        score += 1
        signals.append('tld_riesgo_alto')
        # Si adem√°s hay marca y tokens, reforzar el contexto espa√±ol
        if has_spanish_brand and spanish_token_count >= 1:
            score += 2
            signals.append('foreign_tld_but_es_context')

    # Hostings de riesgo/ingress
    if any(h in netloc for h in ['fsthosting', 'codeanyapp', 'preview-domain', 'cprapid', 'suportededicado']):
        score += 1
        signals.append('suspicious_host')

    # Patr√≥n ingress de ewp.live (campa√±as autom√°ticas)
    if INGRESS_REGEX.search(netloc):
        score += 2
        signals.append('host_ingress_pattern')

    # Shorteners con tokens espa√±oles
    shorteners = ['l.ead.me', 'bit.ly', 't.co', 'tinyurl.com', 'ow.ly', 'is.gd', 'page.link']
    if any(s in netloc for s in shorteners):
        short_tokens = ['es', 'spain', 'bbva', 'correos', 'ing', 'santander', 'caixabank']
        if any(tok in path_lower or tok in query for tok in short_tokens):
            score += 2
            signals.append('shortener_spain')

    # --------------------------------------------------------------
    # 3. Penalizaciones
    # --------------------------------------------------------------
    # TLD latinoamericano
    for tld in LATAM_TLDS:
        if netloc.endswith(tld):
            score -= 2
            signals.append(f'latam_tld:{tld}')
            break

    # Tokens en portugu√©s
    for pt in PORTUGUESE_TOKENS:
        if pt in url_low:
            score -= 2
            signals.append(f'pt_kw:{pt}')
            break

    # Marcas latinoamericanas
    for lb in LATAM_BRANDS:
        if lb in url_low:
            score -= 1
            signals.append(f'latam_brand:{lb}')
            break

    # Tokens ingleses en el path o host cuando hay marca espa√±ola y pocos tokens en espa√±ol
    if has_spanish_brand:
        english_hits = [tok for tok in ENGLISH_TOKENS if tok in url_low]
        # S√≥lo penaliza si la presencia de tokens espa√±oles es baja (0 o 1)
        if english_hits and spanish_token_count <= 1:
            score -= 1
            signals.append('english_term_in_path')

    # Falso positivo de "ing": detectamos si "ing" aparece embebido en palabras
    # m√°s largas (p. ej., hiringindia) sin ser la marca del banco ING.
    ing_false_positive = False
    if 'ing' in url_low:
        # Si la palabra exacta "ing" est√° en alg√∫n label del host, es marca real
        labels = netloc.split('.')
        brand_real = any(label == 'ing' for label in labels)
        # Whitelist de ing leg√≠timo
        if not brand_real and not re.search(r"\bing(\.|-|bank|direct|es|\.es)\b", url_low):
            # Buscar tokens que contienen "ing" dentro de palabras m√°s largas
            for token in re.split(r'[\-/._]', netloc + path):
                if re.search(r'[a-z]+ing[a-z]+', token):
                    ing_false_positive = True
                    break
    if ing_false_positive:
        score -= 2
        signals.append('ing_false_positive')
        # Excepci√≥n: si adem√°s hay tokens espa√±oles ‚Üí compensar
        if spanish_token_count >= 1:
            score += 2
            signals.append('ing_path_exception')

    # Detectar dominios .es comprometidos (WP hack)
    compromised = False
    if '.es' in netloc:
        # Rutas t√©cnicas que indican hackeo de webs leg√≠timas
        if re.search(r'(wp-|plugins|themes|includes|vendor/phpunit|css/|js/|webmail)', path_lower):
            compromised = True
    if compromised:
        score -= 5
        signals.append('compromised_host_es')

    # Fuzzy match con whitelist de dominios leg√≠timos
    for legit in spanish_whitelist:
        if legit in url_low:
            score += 2
            signals.append(f'spanish_whitelist_match:{legit}')
            break
        else:
            sim = fuzz.ratio(core, legit.split('.')[0])
            if sim >= 80:
                score += 2
                signals.append(f'fuzzy_whitelist_match:{legit}:{sim:.0f}')
                break

    return score, ';'.join(signals)


def apply_scoring_v2(df: pd.DataFrame, whitelist_path: Path) -> pd.DataFrame:
    """
    Aplica la funci√≥n ``score_url_v2`` a un DataFrame con una columna ``url``
    y devuelve un nuevo DataFrame con las columnas a√±adidas: ``score_total``,
    ``signals_detected``, ``timestamp`` y ``scoring_version``.

    :param df: DataFrame con una columna ``url``.
    :param whitelist_path: Ruta al fichero de dominios leg√≠timos.
    :return: DataFrame anotado con el scoring v2.
    """
    whitelist = load_spanish_whitelist(whitelist_path)
    df = df.copy()
    logger.info("Aplicando scoring_v2 a %d URLs", len(df))
    df['score_total'], df['signals_detected'] = zip(*df['url'].apply(lambda x: score_url_v2(x, whitelist)))
    df['timestamp'] = datetime.now().isoformat()
    df['scoring_version'] = 'v2 (v1.7)'
    return df


def _read_input_file(input_path: Path) -> pd.DataFrame:
    """Lee un CSV o TXT y devuelve un DataFrame con una columna ``url``."""
    if not input_path.exists():
        raise FileNotFoundError(f"‚ùå Archivo de entrada no encontrado: {input_path}")
    try:
        df = pd.read_csv(input_path)
        if 'url' not in df.columns:
            first_col = df.columns[0]
            df = df[[first_col]].rename(columns={first_col: 'url'})
    except Exception:
        with open(input_path, 'r', encoding='utf-8') as f:
            lines = [l.strip() for l in f if l.strip()]
        df = pd.DataFrame({'url': lines})
    if df.empty:
        raise ValueError(f"‚ö†Ô∏è Archivo de entrada vac√≠o: {input_path}")
    return df[['url']].dropna().reset_index(drop=True)


def main(input_file: Path, whitelist_path: Path, out_dir: Path):
    """
    Lector de fichero, deduplicador y aplicador del scoring.  Se encarga de
    separar las URLs seg√∫n umbrales de puntuaci√≥n (‚â•7, 4‚Äì6, ‚â§4) y guardar
    los resultados en CSVs independientes en ``out_dir``.

    :param input_file: Ruta del fichero de entrada (CSV o TXT).
    :param whitelist_path: Ruta del fichero de whitelist de dominios espa√±oles.
    :param out_dir: Directorio de salida para guardar los resultados.
    """
    if not out_dir.exists():
        raise FileNotFoundError(f"‚ùå Directorio de salida inexistente: {out_dir}")
    df_in = _read_input_file(input_file)
    original_count = len(df_in)

    # Deduplicado b√°sico por URL normalizada
    df_in['url_norm'] = df_in['url'].str.strip().str.lower().str.rstrip('/')
    df_in = df_in.drop_duplicates(subset='url_norm').drop(columns='url_norm').reset_index(drop=True)
    logger.info("üßπ Dedupl. URLs: %d ‚Üí %d (%.2f%% eliminadas)",
                original_count, len(df_in), 100 * (1 - len(df_in)/original_count))

    # Scoring
    df_scored = apply_scoring_v2(df_in, whitelist_path=whitelist_path)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    out_file = out_dir / f"feed_scored_v2_{ts}.csv"
    df_scored.to_csv(out_file, index=False)
    logger.info("‚úÖ Scoring v2 completado ‚Äî %d URLs procesadas", len(df_scored))
    print(f"‚úÖ Output guardado en: {out_file}")

    # Separaci√≥n por score
    base = out_file.stem
    df_gt7 = df_scored[df_scored['score_total'] >= 7]
    df_4to7 = df_scored[(df_scored['score_total'] > 4) & (df_scored['score_total'] < 7)]
    df_le4 = df_scored[df_scored['score_total'] <= 4]
    df_gt7.to_csv(out_dir / f"{base}_score_gt7.csv", index=False)
    df_4to7.to_csv(out_dir / f"{base}_score_4to7.csv", index=False)
    df_le4.to_csv(out_dir / f"{base}_score_le4.csv", index=False)

    print(f"üìÇ Subarchivos guardados en {out_dir}:")
    print(f"  üîπ score ‚â• 7:     {len(df_gt7)} URLs ‚Üí {base}_score_gt7.csv")
    print(f"  üî∏ 4 < score < 7: {len(df_4to7)} URLs ‚Üí {base}_score_4to7.csv")
    print(f"  ‚ö™ score ‚â§ 4:     {len(df_le4)} URLs ‚Üí {base}_score_le4.csv")


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(description="Aplica scoring_v2 a un fichero de URLs")
    parser.add_argument('--input', '-i', required=True, help='Fichero de entrada (CSV o TXT)')
    parser.add_argument('--whitelist', '-w', required=True, help='Whitelist de dominios espa√±oles')
    parser.add_argument('--out', '-o', required=True, help='Directorio de salida para los resultados')
    args = parser.parse_args()
    main(Path(args.input), Path(args.whitelist), Path(args.out))