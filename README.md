
Estado del proyecto:
- Prototipo V2: CERRADO
- Extractor contractual: FEATURES_V3
- FEATURES_V2: OBSOLETO (prohibido)
- No existe un prototipo V3 funcional todavÃ­a


# ğŸ›¡ï¸ Phishing Detector (Prototipo EspaÃ±ol)

![Python](https://img.shields.io/badge/python-3.11-blue.svg)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)


## ğŸ“Œ Contexto  
El phishing es uno de los vectores de ataque mÃ¡s comunes en EspaÃ±a, afectando a todo tipo de sectores, siendo la **banca** el mÃ¡s golpeado (concentrando mÃ¡s del 65% de los ataques).  

Este proyecto construye un **pipeline completo** para la detecciÃ³n de URLs maliciosas en el **contexto espaÃ±ol**, bajo la premisa de que cuanto mÃ¡s especÃ­fico sea el dataset, mejores resultados se obtienen.  

---

## ğŸ¯ Objetivo  
Desarrollar un prototipo **reproducible y explicable** de detecciÃ³n de phishing, capaz de:  
- Diferenciar **URLs legÃ­timas** de **URLs de phishing**.  
- Priorizar el **recall** para minimizar falsos negativos.  
- Mantener **trazabilidad completa**: desde los datos crudos hasta el modelo entrenado.  

---

## ğŸ—‚ï¸ Estructura del proyecto  

```
phishing-detector/
â”‚
â”œâ”€â”€ data/            # Datos crudos, intermedios y finales
â”œâ”€â”€ limpieza/        # Notebooks + documentaciÃ³n de limpieza
â”œâ”€â”€ features/        # IngenierÃ­a de caracterÃ­sticas + grÃ¡ficas
â”œâ”€â”€ EDA/             # AnÃ¡lisis exploratorio
â”œâ”€â”€ entrenamiento/   # Entrenamiento del modelo y resultados
â”œâ”€â”€ models/          # Modelos finales exportados (.joblib, .json)
â”œâ”€â”€ scripts/         # AutomatizaciÃ³n de scraping y feeds
â”œâ”€â”€ logs/            # Logs de ejecuciÃ³n
â””â”€â”€ README.md        # Este archivo
```

---

## âš™ï¸ InstalaciÃ³n  

```bash
git clone https://github.com/AlexusPacicus/phishing-detector.git
cd phishing-detector
pip install -r requirements.txt
```

---

## ğŸš€ Uso  

1. **Recolectar datos**  
   ```bash
   python scripts/aut_openphish.py
   ```

2. **Limpieza manual / heurÃ­stica**  
   Ejecutar notebooks en `limpieza/`.

3. **Entrenar modelo**  
   ```bash
   jupyter notebook entrenamiento/entrenamiento_prototipo.ipynb
   ```

4. **Modelo final guardado en**  
   ```
   models/logreg_phishing_final.joblib
   ```

---

## ğŸ“Š Resultados  

- **Modelo seleccionado**: Logistic Regression  
- **Umbral Ã³ptimo**: `0.425`  
- **MÃ©tricas clave (CV promedio, k=5â€“10):**  
  - Precision â‰ˆ 0.85  
  - Recall â‰ˆ 0.92  
  - ROC-AUC â‰ˆ 0.95  

ğŸ“ˆ **GrÃ¡ficas principales** (en `entrenamiento/img/`):  
- Curva Precision-Recall  
- Matriz de confusiÃ³n  
- ROC-AUC  
- Importancia de features  

---

## ğŸ§© Valor del proyecto  

- Pipeline completo y documentado.  
- Dataset curado especÃ­ficamente para **phishing en EspaÃ±a**.  
- Features explicables y fÃ¡cilmente integrables en un SOC.  
- Preparado para futuras ampliaciones: **SMS, email phishing, integraciÃ³n con SIEM**.  

---

## ğŸ“œ Licencia  

Este proyecto se distribuye bajo licencia **MIT**.  

## ğŸš€ Despliegue con Docker

Este proyecto incluye un `Dockerfile` para levantar la API de forma sencilla en cualquier mÃ¡quina con Docker instalado.

1. Construir la imagen
Desde la raÃ­z del proyecto:
docker build -t phishing-detector .

2. Ejecutar el contenedor
docker run -p 8000:8000 phishing-detector

3. Acceder a la API
Swagger UI â†’ http://127.0.0.1:8000/docs
Healthcheck â†’ http://127.0.0.1:8000/health
PredicciÃ³n (POST /predict) â†’ enviar un JSON con la URL a analizar, por ejemplo:
{
  "url": "https://soporte-netflx.com/"
}

4. Ejemplo de respuesta

{
  "label": 1,
  "probability": 0.7517,
  "threshold": 0.425,
  "features": {
    "domain_length": 14,
    "domain_entropy": 3.37,
    "num_params": 0,
    "trusted_path_token": 0,
    "contains_percent": 0,
    "contains_equal": 0,
    "suspicious_path_token": 0,
    "free_hosting": 0,
    "protocol": 1,
    "tld_group": "com"
  }
}


---

### Tests automÃ¡ticos con Pytest


# ğŸ§ª Tests automÃ¡ticos

Este proyecto incluye pruebas con **pytest** para verificar:

- Que `extract_features()` devuelve las 10 features esperadas.  
- Que la API responde correctamente en `/health` y `/predict`.  

1. Ejecutar los tests
Desde la raÃ­z del proyecto:
pytest -q

2. Ejemplo de salida esperada
....                                                                     [100%]
4 passed in 1.64s

---

## ğŸ”® PrÃ³ximos avances â€“ Fase 3: Inteligencia semÃ¡ntica y detecciÃ³n de ruido

En la siguiente etapa, el proyecto incorporarÃ¡ **anÃ¡lisis vectorial y bÃºsqueda semÃ¡ntica** para reforzar el sistema de scoring y mejorar la calidad del dataset.

### ğŸ¯ Objetivos principales
1. **Representar cada URL como un embedding** â†’ un vector numÃ©rico que capta su significado o estructura.
2. **Calcular un centroide espaÃ±ol** â†’ el punto medio del espacio vectorial de todas las URLs confirmadas como orientadas a EspaÃ±a.
3. **Medir el â€œruido semÃ¡nticoâ€** de cada nueva URL:
   - Se calcula la **similitud del coseno** entre la URL y el centroide espaÃ±ol.
   - Cuanto mÃ¡s baja sea la similitud, mÃ¡s alejada estÃ¡ del patrÃ³n espaÃ±ol y mÃ¡s probable es que sea ruido o irrelevante.
   - Esta medida (`ruido_semantico`) se combinarÃ¡ con el `score_total` actual como seÃ±al adicional.
4. **Almacenar los embeddings en PostgreSQL usando `pgvector`**, para permitir:
   - BÃºsqueda semÃ¡ntica de campaÃ±as parecidas.
   - DetecciÃ³n de variantes o clones.
   - VisualizaciÃ³n de clusters de phishing por marca o sector.

### ğŸ§© Ejemplo conceptual
- URLs espaÃ±olas â†’ agrupadas en torno al centroide.  
- Nueva URL â†’ se mide su distancia (1 - coseno) al centroide.  
- Cuanto mayor la distancia, **mÃ¡s ruido semÃ¡ntico**.  

```text
         Â·        (URLs espaÃ±olas)
       Â·   Â·
         âŠ•  â† Centroide espaÃ±ol
          \
           \_Â·  (URL alejada â†’ alto ruido)



ğŸ§­ PrÃ³ximos pasos â€“ Fase 3 (desde hoy)
1ï¸âƒ£ Preparar dataset de legÃ­timas v2
Objetivo: disponer de ~150 URLs legÃ­timas nuevas para validaciÃ³n y contrapeso.
Tareas:
Recolectar ~200 candidatas (banca, logÃ­stica, SaaS, pÃºblico, retail, criptoâ€¦).
Aplicar los gates definidos (is_https=1, sin hosting gratuito, sin /wp-, etc.).
Deduplicar semÃ¡nticamente (â‰¤95 % similitud).
Seleccionar 150 finales (keep=1) + 15â€“20 como holdout.
ğŸ“„ Entregable: data/processed/legitimas_v2_final.csv
ğŸ“˜ Documentar en: docs/legitimas_v2_calidad.md
2ï¸âƒ£ ValidaciÃ³n con el modelo actual (LogReg v1)
Objetivo: medir el rendimiento real con las 209 phishing + 150 legÃ­timas.
Tareas:
Combinar datasets â†’ eval_set_inclusion1.csv.
Extraer features con tu extract_features() actual.
Ejecutar el modelo (logreg_phishing_final.joblib).
Exportar mÃ©tricas globales y por sector:
precision, recall, F1, matriz de confusiÃ³n.
Listado de falsos negativos priorizados (falsos_negativos_priorizados.csv).
ğŸ“„ Entregables:
outputs/inclusion1_eval/predicciones_eval.csv
docs/evaluacion_inclusion1.md
3ï¸âƒ£ SelecciÃ³n del nuevo bloque de entrenamiento
Objetivo: crear dataset v2 balanceado (â‰ˆ300â€“350 URLs).
Reglas:
Incluir phishing con ruido_estimado â‰¤ 20 y que sean FN o TP en validaciÃ³n.
Capar por entidad (mÃ¡x. 8â€“10 por marca).
AÃ±adir las legÃ­timas v2 seleccionadas.
ğŸ“„ Entregable: data/processed/dataset_entrenamiento_v2.csv
4ï¸âƒ£ Reentrenamiento de modelo (v2)
Objetivo: entrenar, comparar y calibrar modelos.
Tareas:
Entrenar Logistic Regression, RandomForest y SVC.
Usar GroupKFold (evitar leakage por campaÃ±a).
Optimizar umbral: max recall â‰¥ 0.9, precision â‰¥ 0.8.
Exportar modelo + metadata.json.
ğŸ“„ Entregables:
models/logreg_phishing_v2.joblib
docs/entrenamiento_v2.md
5ï¸âƒ£ Inicio de la Fase 3 â€“ Inteligencia semÃ¡ntica
Objetivo: integrar embeddings y detecciÃ³n de ruido semÃ¡ntico.
Tareas:
Generar embeddings (MiniLM / multilingual-distil).
Calcular centroide espaÃ±ol (media de embeddings de campaÃ±as confirmadas).
Medir ruido_semantico = 1 âˆ’ coseno(URL, centroide).
Integrar ruido_semantico al scoring como nueva seÃ±al.
ğŸ“„ Entregables:
notebooks/semantic_noise.ipynb
docs/scoring_v3_plan.md
ğŸ§© RevisiÃ³n recomendada antes de cerrar cada subfase
âœ… Actualizar documentaciÃ³n (docs/â€¦).
âœ… Exportar mÃ©tricas y CSV de salida.
âœ… Anotar observaciones en avance_<fecha>.md.
âœ… Publicar en LinkedIn los hitos clave (validaciÃ³n, embeddings, etc.).
