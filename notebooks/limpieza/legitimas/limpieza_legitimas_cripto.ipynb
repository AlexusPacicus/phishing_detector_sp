{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a028db-bfea-4593-bf18-8f06342570b6",
   "metadata": {},
   "source": [
    "# Limpieza — LEGÍTIMAS (Sector: cripto)\n",
    "\n",
    "**Objetivo**: Normalizar, validar y deduplicar URLs legítimas para su uso en el baseline.\n",
    "\n",
    "- **Entradas**: `data/raw/legitimas/<sector>/*.csv`\n",
    "- **Salida**: `data/processed/legitimas/<sector>/legitimas_<sector>_limpio.csv`\n",
    "- **Última actualización**: 18/08/2025\n",
    "- **Autor**: Alexis Zapico\n",
    "\n",
    "**Definición de Hecho (DoD)**  \n",
    "1) Carga cruda consolidada.  \n",
    "2) Normalización + validación + deduplicado.  \n",
    "3) Métricas básicas impresas.  \n",
    "4) CSV exportado en `processed`.  \n",
    "5) Log añadido a `docs/daily_log.md`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6ad527-1a51-416c-9732-324f6280b108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO_ROOT: /Users/test/Desktop/phishing-detector\n",
      "RAW_DIR: /Users/test/Desktop/phishing-detector/data/raw/legitimas/cripto\n",
      "PROCESSED_DIR: /Users/test/Desktop/phishing-detector/data/processed/legitimas/cripto\n"
     ]
    }
   ],
   "source": [
    "# === RUTAS ===\n",
    "from pathlib import Path\n",
    "\n",
    "def find_repo_root(start: Path = Path().resolve()):\n",
    "    \"\"\"\n",
    "    Sube hasta 10 niveles buscando algo que parezca la raíz del repo:\n",
    "    carpeta 'data', o '.git', o 'README.md'.\n",
    "    \"\"\"\n",
    "    p = start\n",
    "    for _ in range(10):\n",
    "        if (p / \"data\").exists() or (p / \".git\").exists() or (p / \"README.md\").exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return Path().resolve()\n",
    "\n",
    "REPO_ROOT = find_repo_root()\n",
    "DATA_DIR = REPO_ROOT / \"data\"\n",
    "\n",
    "SECTOR = \"cripto\" \n",
    "\n",
    "RAW_DIR = DATA_DIR / \"raw\" / \"legitimas\" / SECTOR\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\" / \"legitimas\" / SECTOR\n",
    "OUT_FILE = PROCESSED_DIR / f\"legitimas_{SECTOR}_limpio.csv\"\n",
    "\n",
    "# crea carpetas necesarias\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(REPO_ROOT / \"docs\").mkdir(exist_ok=True)\n",
    "\n",
    "print(\"REPO_ROOT:\", REPO_ROOT)\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "print(\"PROCESSED_DIR:\", PROCESSED_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce46a69-a7db-4b26-a3d4-e820463ca15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HELPERS ===\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlsplit, urlunsplit, unquote\n",
    "import validators  # pip install validators\n",
    "\n",
    "def es_url_valida(u: str) -> bool:\n",
    "    \"\"\"\n",
    "    True si:\n",
    "    - es str\n",
    "    - no es vacía\n",
    "    - empieza por http/https\n",
    "    - pasa validators.url (sintaxis)\n",
    "    \"\"\"\n",
    "    if not isinstance(u, str):\n",
    "        return False\n",
    "    u = u.strip()\n",
    "    if not u or not u.startswith((\"http://\",\"https://\")):\n",
    "        return False\n",
    "    try:\n",
    "        return bool(validators.url(u))\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def normalizar_url(u: str) -> str:\n",
    "    \"\"\"\n",
    "    Normaliza:\n",
    "    - quita espacios y decodifica %xx\n",
    "    - esquema y host a minúsculas\n",
    "    - reconstruye sin fragment (#...)\n",
    "    \"\"\"\n",
    "    if not isinstance(u, str):\n",
    "        return \"\"\n",
    "    u = unquote(u.strip())\n",
    "    u = re.sub(r\"\\s+\", \"\", u)\n",
    "    try:\n",
    "        sp = urlsplit(u)\n",
    "        scheme = (sp.scheme or \"\").lower()\n",
    "        netloc = (sp.netloc or \"\").lower()\n",
    "        path, query = sp.path or \"\", sp.query or \"\"\n",
    "        return urlunsplit((scheme, netloc, path, query, \"\"))\n",
    "    except Exception:\n",
    "        return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3890e06f-d8c3-44e5-8838-25384853b8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando en: /Users/test/Desktop/phishing-detector/data/raw/legitimas/cripto\n",
      "Encontrados: ['cripto_legitimas_crudo.csv']\n",
      "Archivos leídos:\n",
      " - cripto_legitimas_crudo.csv: 209 filas\n",
      "TOTAL filas crudas: 209\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>__source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>cripto_legitimas_crudo.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>cripto_legitimas_crudo.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.kraken.com/</td>\n",
       "      <td>cripto_legitimas_crudo.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       url               __source_file\n",
       "0                      NaN  cripto_legitimas_crudo.csv\n",
       "1                      NaN  cripto_legitimas_crudo.csv\n",
       "2  https://www.kraken.com/  cripto_legitimas_crudo.csv"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === CARGA CRUDA ROBUSTA ===\n",
    "# Soporta .csv y .CSV, múltiples encodings y columnas diversas para URL\n",
    "CANDIDATES = [\"url\", \"URL\", \"Url\", \"enlace\", \"link\", \"href\"]\n",
    "\n",
    "files = sorted(list(RAW_DIR.glob(\"*.csv\")) + list(RAW_DIR.glob(\"*.CSV\")))\n",
    "print(\"Buscando en:\", RAW_DIR.resolve())\n",
    "print(\"Encontrados:\", [p.name for p in files])\n",
    "assert files, f\"No hay CSV en {RAW_DIR}. Revisa la ruta/nombres.\"\n",
    "\n",
    "def read_csv_tolerant(path: Path):\n",
    "    \"\"\"Prueba varios encodings; salta líneas corruptas sin parar el flujo.\"\"\"\n",
    "    for args in (\n",
    "        dict(),  # por defecto\n",
    "        dict(encoding=\"utf-8\", engine=\"python\", on_bad_lines=\"skip\"),\n",
    "        dict(encoding=\"latin-1\", engine=\"python\", on_bad_lines=\"skip\"),\n",
    "    ):\n",
    "        try:\n",
    "            return pd.read_csv(path, **args)\n",
    "        except Exception:\n",
    "            continue\n",
    "    raise RuntimeError(f\"No se pudo leer {path.name} con los encodings probados.\")\n",
    "\n",
    "dfs, per_file_counts, skipped = [], [], []\n",
    "for f in files:\n",
    "    try:\n",
    "        d = read_csv_tolerant(f)\n",
    "        col_url = next((c for c in CANDIDATES if c in d.columns), None)\n",
    "        if not col_url:\n",
    "            raise KeyError(f\"{f.name} sin columna URL reconocida {CANDIDATES}\")\n",
    "        d = d[[col_url]].rename(columns={col_url: \"url\"}).copy()\n",
    "        d[\"__source_file\"] = f.name\n",
    "        dfs.append(d)\n",
    "        per_file_counts.append((f.name, len(d)))\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Saltando {f.name}: {e}\")\n",
    "        skipped.append((f.name, str(e)))\n",
    "\n",
    "assert dfs, \"Ningún CSV válido. Revisa los [WARN] y corrige.\"\n",
    "df_raw = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(\"Archivos leídos:\")\n",
    "for n, k in per_file_counts:\n",
    "    print(f\" - {n}: {k} filas\")\n",
    "print(\"TOTAL filas crudas:\", len(df_raw))\n",
    "df_raw.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b604ba-8b33-4d96-925d-9f5f80aae0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas tras limpieza: 205\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>__source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.kraken.com/</td>\n",
       "      <td>cripto_legitimas_crudo.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://bit2me.com/buy-axie-infinity</td>\n",
       "      <td>cripto_legitimas_crudo.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://bit2me.com/suite/custody</td>\n",
       "      <td>cripto_legitimas_crudo.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://bit2me.com/buy-cardano</td>\n",
       "      <td>cripto_legitimas_crudo.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://bit2me.com/suite</td>\n",
       "      <td>cripto_legitimas_crudo.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    url               __source_file\n",
       "0               https://www.kraken.com/  cripto_legitimas_crudo.csv\n",
       "1  https://bit2me.com/buy-axie-infinity  cripto_legitimas_crudo.csv\n",
       "2      https://bit2me.com/suite/custody  cripto_legitimas_crudo.csv\n",
       "3        https://bit2me.com/buy-cardano  cripto_legitimas_crudo.csv\n",
       "4              https://bit2me.com/suite  cripto_legitimas_crudo.csv"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === LIMPIEZA ===\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Normaliza URL (espacios, %xx, esquema/host)\n",
    "df[\"url\"] = df[\"url\"].map(normalizar_url)\n",
    "\n",
    "# Valida URL (http/https + sintaxis ok)\n",
    "df = df[df[\"url\"].map(es_url_valida)]\n",
    "\n",
    "# Quita nulos explícitos\n",
    "df = df.dropna(subset=[\"url\"])\n",
    "\n",
    "# Dedup exacto por URL\n",
    "df = df.drop_duplicates(subset=[\"url\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Filas tras limpieza:\", len(df))\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7fc1ac-c250-41f3-b73f-8684b36a8285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filas_crudas': 209,\n",
       " 'filas_limpias': 205,\n",
       " '%https': np.float64(100.0),\n",
       " 'longitud_media': np.float64(38.19)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === MÉTRICAS RÁPIDAS ===\n",
    "resumen = {\n",
    "    \"filas_crudas\": len(df_raw),\n",
    "    \"filas_limpias\": len(df),\n",
    "    \"%https\": round(df[\"url\"].str.startswith(\"https://\").mean()*100, 2),\n",
    "    \"longitud_media\": round(df[\"url\"].str.len().mean(), 2),\n",
    "}\n",
    "resumen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21177029-cb8b-4277-9823-9d967ae757ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url\n",
       "bit2me.com            91\n",
       "www.etoro.com         91\n",
       "academy.bit2me.com     7\n",
       "app.bit2me.com         2\n",
       "blog.bit2me.com        2\n",
       "www.kraken.com         1\n",
       "empleo.bit2me.com      1\n",
       "support.bit2me.com     1\n",
       "news.bit2me.com        1\n",
       "status.bit2me.com      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = df[\"url\"].str.extract(r\"^https?://([^/]+)/\", expand=False).str.lower()\n",
    "tmp.value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54683779-ede0-4415-96a3-62f5fb395674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: /Users/test/Desktop/phishing-detector/data/processed/legitimas/cripto/legitimas_cripto_limpio.csv\n",
      "Log añadido: 2025-08-18 | limpieza_legitimas_cripto | crudo=209 | limpio=205 | out=/Users/test/Desktop/phishing-detector/data/processed/legitimas/cripto/legitimas_cripto_limpio.csv\n"
     ]
    }
   ],
   "source": [
    "# === EXPORT ===\n",
    "df.to_csv(OUT_FILE, index=False)\n",
    "print(\"Guardado en:\", OUT_FILE)\n",
    "\n",
    "# === LOG (docs/daily_log.md) ===\n",
    "log_line = (\n",
    "    f\"{datetime.now():%Y-%m-%d} | limpieza_legitimas_{SECTOR} | \"\n",
    "    f\"crudo={len(df_raw)} | limpio={len(df)} | out={OUT_FILE}\\n\"\n",
    ")\n",
    "with open(REPO_ROOT / \"docs\" / \"daily_log.md\", \"a\") as f:\n",
    "    f.write(log_line)\n",
    "\n",
    "print(\"Log añadido:\", log_line.strip())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
