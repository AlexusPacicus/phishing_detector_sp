# ðŸ“‘ Contrato de salida â€“ Endpoint `/predict_explain`

Este documento define el **contrato JSON de salida** del nuevo endpoint `/predict_explain`, que integra el modelo de detecciÃ³n de phishing con explicabilidad generada vÃ­a Azure OpenAI.

---

## ðŸ”¹ Ejemplo de salida

```json
{
  "request_id": "b3e29c92-76f7-44b5-9c78-fbcd2f25b123",
  "timestamp": "2025-09-25T14:00:00Z",
  "url": "https://soporte-netflx.com/",
  "label": 1,
  "probability": 0.7517,
  "threshold": 0.425,
  "features": {
    "domain_length": 14,
    "domain_entropy": 3.37,
    "num_params": 0,
    "trusted_path_token": 0,
    "contains_percent": 0,
    "contains_equal": 0,
    "suspicious_path_token": 0,
    "free_hosting": 0,
    "protocol": 1,
    "tld_group": "com"
  },
  "explanation": "Clasificada como phishing porque usa hosting gratuito, un TLD sospechoso y muestra entropÃ­a de dominio elevada.",
  "reasons": [
    {"feature": "free_hosting", "evidence": "dominio en hosting gratuito", "weight": "alta"},
    {"feature": "tld_group", "evidence": "TLD fuera del grupo seguro", "weight": "media"},
    {"feature": "domain_entropy", "evidence": "entropÃ­a de dominio elevada", "weight": "baja"}
  ],
  "model_version": "logreg_v1.0",
  "prompt_version": "azure_v1"
}
 
 
 ðŸ”¹ Campos obligatorios

request_id â†’ UUID Ãºnico para trazabilidad.
timestamp â†’ Fecha/hora en formato ISO 8601 (UTC).
url â†’ La URL analizada.
label â†’ 0 = legÃ­tima, 1 = phishing.
probability â†’ Score de probabilidad del modelo (float).
threshold â†’ Umbral de decisiÃ³n, fijado en 0.425.
features â†’ Diccionario con las 10 features seleccionadas:
domain_length
domain_entropy
num_params
trusted_path_token
contains_percent
contains_equal
suspicious_path_token
free_hosting
protocol
tld_group
explanation â†’ ExplicaciÃ³n generada por Azure OpenAI en castellano (2â€“4 frases).
reasons â†’ Lista de mÃ¡x. 3 razones en formato {feature, evidence, weight}.
model_version â†’ "logreg_v1.0".
prompt_version â†’ VersiÃ³n del prompt usado, ej. "azure_v1".


ðŸ”¹ Casos especiales

Si la llamada a Azure OpenAI falla (timeout, error de cuota, etc.), la respuesta incluirÃ¡:
{
  "explanation": null,
  "reasons": [],
  "explanation_note": "LLM_unavailable"
}


ðŸ”¹ Notas

El contrato asegura consistencia para testing automÃ¡tico y trazabilidad en auditorÃ­as.
Los campos model_version y prompt_version permiten versionar tanto el modelo como el prompt.
Se recomienda almacenar cada respuesta en Azure Blob Storage para auditorÃ­a (logs/prediction_{fecha}/{request_id}.json).
