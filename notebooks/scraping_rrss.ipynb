{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b43596c0-d53d-4def-bee9-a84bf25c3bb6",
   "metadata": {},
   "source": [
    "## Redes Sociales: Scraping de URLs\n",
    "\n",
    "**Fecha de ejecución:** 22/07/2025  \n",
    "**Empresas objetivo:**  \n",
    "Facebook, Instagram, LinkedIn, Twitter/X, TikTok, Snapchat, Pinterest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6591db3-d2bf-4d97-9f1e-d4927438d3bd",
   "metadata": {},
   "source": [
    "| Empresa      | URLs únicas | Fecha      | Estado / Observaciones                                |\n",
    "|--------------|------------|------------|-------------------------------------------------------|\n",
    "| Facebook     |     2      | 22/07/2025 | OK – Home minimalista, muy pocos enlaces              |\n",
    "| Instagram    |     0      | 22/07/2025 | No scrapeado – Home bloqueada/login requerido         |\n",
    "| LinkedIn     |    151     | 22/07/2025 | OK – Muchas URLs públicas                             |\n",
    "| Twitter/X    |     5      | 22/07/2025 | OK – Pocos enlaces relevantes                         |\n",
    "| TikTok       |     0      | 22/07/2025 | No scrapeado – Home bloqueada/login requerido         |\n",
    "| Snapchat     |    20      | 22/07/2025 | OK – Algunos enlaces accesibles                       |\n",
    "| Pinterest    |     0      | 22/07/2025 | No scrapeado – Home bloqueada/login requerido         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b54d61f-81cb-4801-a232-051291dc744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd, os\n",
    "import time\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e09a0fb-2ab5-433f-8b1f-f2b7595f9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "empresas_rrss = {\n",
    "    \"Facebook\": \"https://www.facebook.com\",\n",
    "    \"Instagram\": \"https://www.instagram.com\",\n",
    "    \"LinkedIn\": \"https://www.linkedin.com\",\n",
    "    \"Twitter/X\": \"https://twitter.com\",\n",
    "    \"TikTok\": \"https://www.tiktok.com\",\n",
    "    \"Snapchat\": \"https://www.snapchat.com\",\n",
    "    \"Pinterest\": \"https://www.pinterest.es\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e46afb01-7ad1-4c9c-9199-01d21793f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def obtener_urls(base_url, delay=1):\n",
    "    \"\"\"\n",
    "    Descarga la página principal y extrae las URLs internas.\n",
    "    Solo acepta URLs del dominio principal y subdominios.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        }\n",
    "        response = requests.get(base_url, timeout=10, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        dominio_empresa = urlparse(base_url).netloc\n",
    "\n",
    "        # Elimina \"www.\" al inicio para igualar subdominios y dominio principal\n",
    "        dominio_base = dominio_empresa[4:] if dominio_empresa.startswith('www.') else dominio_empresa\n",
    "\n",
    "        urls = set()\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link['href']\n",
    "            href = urljoin(base_url, href)\n",
    "            dominio_href = urlparse(href).netloc\n",
    "            dominio_href_base = dominio_href[4:] if dominio_href.startswith('www.') else dominio_href\n",
    "\n",
    "            if dominio_href_base == dominio_base or dominio_href_base.endswith('.' + dominio_base):\n",
    "                urls.add(href)\n",
    "\n",
    "        time.sleep(delay)  # Añade delay entre requests si scrapeas en lote\n",
    "        return list(urls)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error al acceder a {base_url}: {e}')\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1025a84-d07a-479d-ae05-137877d92b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping empresa: Facebook\n",
      "Scraping empresa: Instagram\n",
      "Scraping empresa: LinkedIn\n",
      "Scraping empresa: Twitter/X\n",
      "Scraping empresa: TikTok\n",
      "Scraping empresa: Snapchat\n",
      "Scraping empresa: Pinterest\n"
     ]
    }
   ],
   "source": [
    "resultados = []\n",
    "for nombre, url_base in empresas_rrss.items():\n",
    "    print(f'Scraping empresa: {nombre}')\n",
    "    urls_empresa = obtener_urls(url_base)\n",
    "    for url in urls_empresa:\n",
    "        resultados.append({'empresa': nombre, 'url': url})\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ff6ed6e-c890-49c9-b2f8-6eb8e8c680ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrap = pd.DataFrame(resultados)\n",
    "df_scrap.to_csv('../data/raw/rrss_legitimas_crudo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced62a00-e64e-49a8-bf5f-6d1b9b0d2eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empresa\n",
      "LinkedIn     151\n",
      "Snapchat      20\n",
      "Twitter/X      5\n",
      "Facebook       2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_scrap['empresa'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3dc2b1-85f3-46ad-bcef-674bbfff870a",
   "metadata": {},
   "source": [
    "- **Empresas objetivo:** 7  \n",
    "- **Empresas con resultados:** 4 (Facebook, LinkedIn, Twitter/X, Snapchat)\n",
    "- **Empresas sin datos:** 3 (Instagram, TikTok, Pinterest)\n",
    "- **Motivo:** Las homes de Instagram, TikTok y Pinterest requieren login o están bloqueadas para scraping anónimo.\n",
    "- **Observaciones:**  \n",
    "  - En RRSS es habitual que solo consigas datos en páginas realmente abiertas al público, el resto son privadas/ocultas.\n",
    "  - LinkedIn es la excepción porque expone más URLs públicas.\n",
    "- **Acción futura:**  \n",
    "  - Si necesitas más datos de estas plataformas, habrá que probar técnicas avanzadas (selenium, autenticación, scraping indirecto, etc.), pero para un proyecto de demo/entrevista esto es suficiente si lo documentas así.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (phishing-env)",
   "language": "python",
   "name": "phishing-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
